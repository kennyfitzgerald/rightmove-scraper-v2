name: Property Scraper

on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:
    inputs:
      reset_db:
        description: 'Wipe the DB and artifacts this run only'
        type: boolean
        required: false
        default: false

env:
  TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
  GOOGLE_SHEETS_CREDENTIALS_JSON: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS_JSON }}
  GOOGLE_SHEETS_URL: ${{ secrets.GOOGLE_SHEETS_URL }}

concurrency:
  group: property-scraper
  cancel-in-progress: false

jobs:
  scrape-properties:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Fresh build only when resetting (optional but helpful)
      - name: Build Docker image
        run: |
          if [ "${{ github.event.inputs.reset_db }}" = "true" ]; then
            docker compose build --no-cache --pull property-scraper
          else
            docker compose build property-scraper
          fi

      - name: Create data directory
        run: mkdir -p data

      # ðŸ§¨ ONE-TIME RESET (when triggered manually with reset_db: true)
      - name: One-time DB reset (delete local DB + old artifacts)
        if: ${{ github.event.inputs.reset_db == 'true' }}
        run: |
          echo "Resetting database for this run only..."
          rm -f ./data/properties.db
          # Delete all existing artifacts named 'property-database' so they won't be restored later
          ids=$(gh api repos/${{ github.repository }}/actions/artifacts --paginate \
            --jq '.artifacts[] | select(.name=="property-database") | .id')
          if [ -n "$ids" ]; then
            for id in $ids; do
              echo "Deleting artifact id $id"
              gh api -X DELETE repos/${{ github.repository }}/actions/artifacts/$id
            done
          else
            echo "No existing 'property-database' artifacts found."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Only download the previous DB when NOT resetting
      - name: Download previous database (if exists)
        if: ${{ github.event.inputs.reset_db != 'true' }}
        continue-on-error: true
        run: |
          gh api repos/${{ github.repository }}/actions/artifacts \
            --jq '.artifacts[] | select(.name=="property-database") | select(.expired==false) | .archive_download_url' \
            | head -1 \
            | xargs -I {} gh api {} > database.zip || true
          if [ -f database.zip ]; then
            unzip -o database.zip -d ./data/ || true
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Test configuration
        run: |
          docker compose run --rm \
            -e TELEGRAM_BOT_TOKEN="$TELEGRAM_BOT_TOKEN" \
            -e GOOGLE_SHEETS_CREDENTIALS_JSON="$GOOGLE_SHEETS_CREDENTIALS_JSON" \
            property-scraper python src/main.py --test-config --sheets-url "$GOOGLE_SHEETS_URL"

      - name: Run property scraper (once)
        run: |
          docker compose run --rm \
            -e TELEGRAM_BOT_TOKEN="$TELEGRAM_BOT_TOKEN" \
            -e GOOGLE_SHEETS_CREDENTIALS_JSON="$GOOGLE_SHEETS_CREDENTIALS_JSON" \
            property-scraper python src/main.py --run-once --sheets-url "$GOOGLE_SHEETS_URL"

      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: property-database
          path: ./data/properties.db
          retention-days: 30

      - name: Upload logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: scraper-logs
          path: ./data/scraper.log
          retention-days: 7
